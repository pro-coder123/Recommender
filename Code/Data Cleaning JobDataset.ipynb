{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the entire dataset\n",
    "data = pd.read_csv('../Results/JobsDataset.csv', header = 0, names = ['Query', 'Job Title', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Job Descriptions Cleaning\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "symbols_to_ignore = ['(', ')', '.', '\\\\', ':', '%', 'â€™']\n",
    "to_ignore = stopwords.words('english')\n",
    "to_ignore.extend(symbols_to_ignore)\n",
    "\n",
    "cleaned_jobs = []\n",
    "for job in data.Description:\n",
    "\n",
    "\t#Convert to lowercase and remove some symbols from the start\n",
    "    lower_job = job.lower().replace(',', '').replace('_', '').replace(';', '')\n",
    "    \n",
    "    #Tokenize into words\n",
    "    words_1 = word_tokenize(lower_job)\n",
    "\n",
    "    #Lemmatize the words\n",
    "    words_2 = [lemmatizer.lemmatize(w) for w in words_1]\n",
    "\n",
    "    #Skip stopwords and some extra symbols (see line 3)\n",
    "    words_3 = [w for w in words_2 if not w in to_ignore]\n",
    "\n",
    "    #Join the tokens into a string and store it\n",
    "    clean_job = \" \".join(words_3)\n",
    "    cleaned_jobs.append(clean_job)\n",
    "\n",
    "## Job Query Titles Cleaning (for reporting purposes, to deal with search keywords)\n",
    "cleaned_queries = []\n",
    "for query in data.Query:\n",
    "\n",
    "\tif query == \"Statistics\":\n",
    "\t\tquery = \"Statistician\"\n",
    "\telif query in [\"Artificial Intelligence\", \"Deep Learning\"]:\n",
    "\t\tquery = query + ' Expert'\n",
    "\telif query in [\"Technical Operations\", \"Machine Learning\"]:\n",
    "\t\tquery = query + ' Engineer'\n",
    "\telif query in [\"Data Warehousing\", \"Technology Integration\"]:\n",
    "\t\tquery = query + ' Analyst'\n",
    "\n",
    "\tcleaned_queries.append(query)\n",
    "                                                            \n",
    "## Create new df\n",
    "df = pd.DataFrame({'Query':cleaned_queries, 'Description':cleaned_jobs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create csv \n",
    "df.to_csv('../Results/Cleaned_JobDescs.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
