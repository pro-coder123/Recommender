{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Embedding, LSTM\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import metrics, regularizers\n",
    "from keras.preprocessing import sequence\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cleaned dataset\n",
    "data = pd.read_csv('../../Results/Cleaned_JobDescs.csv', header = 0, names = ['Query', 'Description'])\n",
    "#data = pd.read_csv('../../Results/Cleaned_JobsNonIT.csv', header = 0, names = ['Query', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset to Training and Test subsets (90/10)\n",
    "train, test = train_test_split(data, test_size = 0.1, random_state = 17) #random_state = None\n",
    "\n",
    "train_descs = train['Description']\n",
    "train_labels = train['Query']\n",
    " \n",
    "test_descs = test['Description']\n",
    "test_labels = test['Query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "vocab_size = 2000\n",
    "\n",
    "sequences_length = 1200\n",
    "\n",
    "embedding_dimensionality = 64 #possibly low??\n",
    "max_features = 2000 #equal to vocab_size\n",
    "\n",
    "num_labels = len(train_labels.unique())\n",
    "batch_size = 32\n",
    "nb_epoch = 20\n",
    "\n",
    "nof_filters = 200 #check + research ... random now\n",
    "kernel_size = 16 #check + research ... random now\n",
    "\n",
    "hidden_dims = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Texts to Numeric Vectors for Input\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(train_descs)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(train_descs)\n",
    "x_test = tokenizer.texts_to_sequences(test_descs)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = sequences_length, padding = 'post')\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = sequences_length, padding = 'post')\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_labels)\n",
    "y_train = encoder.transform(train_labels)\n",
    "y_test = encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 1200, 64)          128000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1185, 200)         205000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              205824    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                25625     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 25)                0         \n",
      "=================================================================\n",
      "Total params: 564,449\n",
      "Trainable params: 564,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embedding_dimensionality, input_length = 1200))\n",
    "#model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Conv1D(nof_filters, kernel_size, padding='valid', activation='relu', strides = 1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', #'sgd', 'adam', 'RMSprop', 'Adagrad'\n",
    "                   metrics = [metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/20\n",
      "7200/7200 [==============================] - 189s 26ms/step - loss: 2.9082 - categorical_accuracy: 0.1293 - val_loss: 2.2397 - val_categorical_accuracy: 0.2750\n",
      "Epoch 2/20\n",
      "7200/7200 [==============================] - 219s 30ms/step - loss: 1.7917 - categorical_accuracy: 0.4361 - val_loss: 1.4972 - val_categorical_accuracy: 0.5378\n",
      "Epoch 3/20\n",
      "7200/7200 [==============================] - 217s 30ms/step - loss: 1.1039 - categorical_accuracy: 0.6501 - val_loss: 1.2234 - val_categorical_accuracy: 0.6200\n",
      "Epoch 4/20\n",
      "7200/7200 [==============================] - 232s 32ms/step - loss: 0.6795 - categorical_accuracy: 0.7846 - val_loss: 1.2003 - val_categorical_accuracy: 0.6339\n",
      "Epoch 5/20\n",
      "7200/7200 [==============================] - 261s 36ms/step - loss: 0.3902 - categorical_accuracy: 0.8856 - val_loss: 1.3220 - val_categorical_accuracy: 0.6328\n",
      "Epoch 6/20\n",
      "7200/7200 [==============================] - 254s 35ms/step - loss: 0.2275 - categorical_accuracy: 0.9401 - val_loss: 1.3599 - val_categorical_accuracy: 0.6506\n",
      "Epoch 7/20\n",
      "7200/7200 [==============================] - 262s 36ms/step - loss: 0.1506 - categorical_accuracy: 0.9701 - val_loss: 1.4561 - val_categorical_accuracy: 0.6389\n",
      "Epoch 8/20\n",
      "7200/7200 [==============================] - 253s 35ms/step - loss: 0.1250 - categorical_accuracy: 0.9782 - val_loss: 1.4638 - val_categorical_accuracy: 0.6517\n",
      "Epoch 9/20\n",
      "7200/7200 [==============================] - 236s 33ms/step - loss: 0.1181 - categorical_accuracy: 0.9810 - val_loss: 1.5172 - val_categorical_accuracy: 0.6372\n",
      "Epoch 10/20\n",
      "7200/7200 [==============================] - 241s 33ms/step - loss: 0.0984 - categorical_accuracy: 0.9835 - val_loss: 1.5531 - val_categorical_accuracy: 0.6511\n",
      "Epoch 11/20\n",
      "7200/7200 [==============================] - 261s 36ms/step - loss: 0.0978 - categorical_accuracy: 0.9840 - val_loss: 1.6153 - val_categorical_accuracy: 0.6417\n",
      "Epoch 12/20\n",
      "7200/7200 [==============================] - 260s 36ms/step - loss: 0.0952 - categorical_accuracy: 0.9840 - val_loss: 1.5415 - val_categorical_accuracy: 0.6478\n",
      "Epoch 13/20\n",
      "7200/7200 [==============================] - 244s 34ms/step - loss: 0.0858 - categorical_accuracy: 0.9850 - val_loss: 1.5845 - val_categorical_accuracy: 0.6411\n",
      "Epoch 14/20\n",
      "7200/7200 [==============================] - 234s 32ms/step - loss: 0.0774 - categorical_accuracy: 0.9858 - val_loss: 1.6201 - val_categorical_accuracy: 0.6494\n",
      "Epoch 15/20\n",
      "7200/7200 [==============================] - 248s 34ms/step - loss: 0.0721 - categorical_accuracy: 0.9867 - val_loss: 1.6263 - val_categorical_accuracy: 0.6533\n",
      "Epoch 16/20\n",
      "7200/7200 [==============================] - 252s 35ms/step - loss: 0.0687 - categorical_accuracy: 0.9860 - val_loss: 1.6785 - val_categorical_accuracy: 0.6506\n",
      "Epoch 17/20\n",
      "7200/7200 [==============================] - 239s 33ms/step - loss: 0.0638 - categorical_accuracy: 0.9876 - val_loss: 1.6918 - val_categorical_accuracy: 0.6467\n",
      "Epoch 18/20\n",
      "7200/7200 [==============================] - 237s 33ms/step - loss: 0.0545 - categorical_accuracy: 0.9881 - val_loss: 1.6910 - val_categorical_accuracy: 0.6533\n",
      "Epoch 19/20\n",
      "7200/7200 [==============================] - 236s 33ms/step - loss: 0.0526 - categorical_accuracy: 0.9885 - val_loss: 1.8099 - val_categorical_accuracy: 0.6489\n",
      "Epoch 20/20\n",
      "7200/7200 [==============================] - 238s 33ms/step - loss: 0.0597 - categorical_accuracy: 0.9857 - val_loss: 1.7618 - val_categorical_accuracy: 0.6472\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = nb_epoch,\n",
    "                    verbose = True,\n",
    "                    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 9s 9ms/step\n",
      "\n",
      "Test categorical_crossentropy: 1.7260095990896225\n",
      "Categorical accuracy: 0.651\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size = batch_size, verbose = True)\n",
    " \n",
    "print('\\nTest categorical_crossentropy:', score[0])\n",
    "print('Categorical accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
