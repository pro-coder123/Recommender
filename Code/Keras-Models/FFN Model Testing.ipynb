{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras import metrics, regularizers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cleaned dataset\n",
    "data = pd.read_csv('../../Results/Cleaned_JobDescs.csv', header = 0, names = ['Query', 'Description'])\n",
    "#data = pd.read_csv('../../Results/Cleaned_JobsNonIT.csv', header = 0, names = ['Query', 'Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset to Training and Test subsets (90/10)\n",
    "train, test = train_test_split(data, test_size = 0.1, random_state = 17) #random_state = None\n",
    "\n",
    "train_descs = train['Description']\n",
    "train_labels = train['Query']\n",
    " \n",
    "test_descs = test['Description']\n",
    "test_labels = test['Query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "num_labels = len(train_labels.unique())\n",
    "vocab_size = 2000\n",
    "batch_size = 32\n",
    "nb_epoch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Texts to Numeric Vectors for Input\n",
    "tokenizer = Tokenizer(num_words = vocab_size)\n",
    "tokenizer.fit_on_texts(train_descs)\n",
    "x_train = tokenizer.texts_to_matrix(train_descs, mode = 'tfidf') #count, tfidf, binary\n",
    "x_test = tokenizer.texts_to_matrix(test_descs, mode = 'tfidf')\n",
    "\n",
    "#print(tokenizer.word_index[0:5000]) #see the first 5000 corpus words, ordered by frequency\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_labels)\n",
    "y_train = encoder.transform(train_labels)\n",
    "y_test = encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 2000)              4002000   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              2001000   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                12525     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 25)                0         \n",
      "=================================================================\n",
      "Total params: 6,516,025\n",
      "Trainable params: 6,516,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2000, input_shape=(vocab_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1000))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    " \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = 'sgd', #'sgd', 'adam', 'RMSprop', 'Adagrad'\n",
    "              metrics = [metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 2.7062 - categorical_accuracy: 0.2350 - val_loss: 2.0554 - val_categorical_accuracy: 0.4361\n",
      "Epoch 2/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.6793 - categorical_accuracy: 0.5258 - val_loss: 1.5881 - val_categorical_accuracy: 0.5394\n",
      "Epoch 3/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.1714 - categorical_accuracy: 0.6658 - val_loss: 1.4221 - val_categorical_accuracy: 0.5778\n",
      "Epoch 4/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.8366 - categorical_accuracy: 0.7663 - val_loss: 1.3425 - val_categorical_accuracy: 0.5983\n",
      "Epoch 5/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.6028 - categorical_accuracy: 0.8408 - val_loss: 1.2831 - val_categorical_accuracy: 0.6139\n",
      "Epoch 6/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4368 - categorical_accuracy: 0.8911 - val_loss: 1.2975 - val_categorical_accuracy: 0.6139\n",
      "Epoch 7/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3218 - categorical_accuracy: 0.9274 - val_loss: 1.2839 - val_categorical_accuracy: 0.6322\n",
      "Epoch 8/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2425 - categorical_accuracy: 0.9490 - val_loss: 1.3201 - val_categorical_accuracy: 0.6250\n",
      "Epoch 9/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.1896 - categorical_accuracy: 0.9636 - val_loss: 1.3188 - val_categorical_accuracy: 0.6278\n",
      "Epoch 10/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.1573 - categorical_accuracy: 0.9722 - val_loss: 1.3598 - val_categorical_accuracy: 0.6178\n",
      "Epoch 11/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.1327 - categorical_accuracy: 0.9775 - val_loss: 1.3528 - val_categorical_accuracy: 0.6200\n",
      "Epoch 12/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.1199 - categorical_accuracy: 0.9775 - val_loss: 1.3856 - val_categorical_accuracy: 0.6244\n",
      "Epoch 13/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.1061 - categorical_accuracy: 0.9817 - val_loss: 1.3901 - val_categorical_accuracy: 0.6300\n",
      "Epoch 14/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.0891 - categorical_accuracy: 0.9844 - val_loss: 1.4100 - val_categorical_accuracy: 0.6294\n",
      "Epoch 15/50\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.0829 - categorical_accuracy: 0.9844 - val_loss: 1.4346 - val_categorical_accuracy: 0.6317\n",
      "Epoch 16/50\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.0741 - categorical_accuracy: 0.9864 - val_loss: 1.4449 - val_categorical_accuracy: 0.6278\n",
      "Epoch 17/50\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.0740 - categorical_accuracy: 0.9840 - val_loss: 1.4485 - val_categorical_accuracy: 0.6356\n",
      "Epoch 18/50\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.0651 - categorical_accuracy: 0.9857 - val_loss: 1.4771 - val_categorical_accuracy: 0.6311\n",
      "Epoch 19/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0665 - categorical_accuracy: 0.9861 - val_loss: 1.4807 - val_categorical_accuracy: 0.6339\n",
      "Epoch 20/50\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.0595 - categorical_accuracy: 0.9875 - val_loss: 1.4808 - val_categorical_accuracy: 0.6367\n",
      "Epoch 21/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0618 - categorical_accuracy: 0.9871 - val_loss: 1.4908 - val_categorical_accuracy: 0.6322\n",
      "Epoch 22/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0560 - categorical_accuracy: 0.9867 - val_loss: 1.5071 - val_categorical_accuracy: 0.6294\n",
      "Epoch 23/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0538 - categorical_accuracy: 0.9858 - val_loss: 1.5274 - val_categorical_accuracy: 0.6250\n",
      "Epoch 24/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0541 - categorical_accuracy: 0.9878 - val_loss: 1.5126 - val_categorical_accuracy: 0.6300\n",
      "Epoch 25/50\n",
      "7200/7200 [==============================] - 21s 3ms/step - loss: 0.0520 - categorical_accuracy: 0.9881 - val_loss: 1.5370 - val_categorical_accuracy: 0.6333\n",
      "Epoch 26/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0524 - categorical_accuracy: 0.9861 - val_loss: 1.5397 - val_categorical_accuracy: 0.6233\n",
      "Epoch 27/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0496 - categorical_accuracy: 0.9876 - val_loss: 1.5775 - val_categorical_accuracy: 0.6256\n",
      "Epoch 28/50\n",
      "7200/7200 [==============================] - 21s 3ms/step - loss: 0.0495 - categorical_accuracy: 0.9874 - val_loss: 1.5560 - val_categorical_accuracy: 0.6283\n",
      "Epoch 29/50\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.0526 - categorical_accuracy: 0.9847 - val_loss: 1.5615 - val_categorical_accuracy: 0.6267\n",
      "Epoch 30/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0461 - categorical_accuracy: 0.9872 - val_loss: 1.5655 - val_categorical_accuracy: 0.6333\n",
      "Epoch 31/50\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.0446 - categorical_accuracy: 0.9875 - val_loss: 1.5766 - val_categorical_accuracy: 0.6328\n",
      "Epoch 32/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0458 - categorical_accuracy: 0.9867 - val_loss: 1.5859 - val_categorical_accuracy: 0.6311\n",
      "Epoch 33/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0468 - categorical_accuracy: 0.9872 - val_loss: 1.5796 - val_categorical_accuracy: 0.6272\n",
      "Epoch 34/50\n",
      "7200/7200 [==============================] - 21s 3ms/step - loss: 0.0416 - categorical_accuracy: 0.9872 - val_loss: 1.6190 - val_categorical_accuracy: 0.6244\n",
      "Epoch 35/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0455 - categorical_accuracy: 0.9867 - val_loss: 1.6066 - val_categorical_accuracy: 0.6311\n",
      "Epoch 36/50\n",
      "7200/7200 [==============================] - 21s 3ms/step - loss: 0.0420 - categorical_accuracy: 0.9876 - val_loss: 1.5928 - val_categorical_accuracy: 0.6317\n",
      "Epoch 37/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0417 - categorical_accuracy: 0.9874 - val_loss: 1.5958 - val_categorical_accuracy: 0.6317\n",
      "Epoch 38/50\n",
      "7200/7200 [==============================] - 21s 3ms/step - loss: 0.0413 - categorical_accuracy: 0.9879 - val_loss: 1.6077 - val_categorical_accuracy: 0.6267\n",
      "Epoch 39/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0376 - categorical_accuracy: 0.9885 - val_loss: 1.6213 - val_categorical_accuracy: 0.6350\n",
      "Epoch 40/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0436 - categorical_accuracy: 0.9879 - val_loss: 1.6171 - val_categorical_accuracy: 0.6372\n",
      "Epoch 41/50\n",
      "7200/7200 [==============================] - 21s 3ms/step - loss: 0.0390 - categorical_accuracy: 0.9881 - val_loss: 1.6228 - val_categorical_accuracy: 0.6317\n",
      "Epoch 42/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0374 - categorical_accuracy: 0.9875 - val_loss: 1.6391 - val_categorical_accuracy: 0.6267\n",
      "Epoch 43/50\n",
      "7200/7200 [==============================] - 22s 3ms/step - loss: 0.0377 - categorical_accuracy: 0.9874 - val_loss: 1.6410 - val_categorical_accuracy: 0.6344\n",
      "Epoch 44/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0370 - categorical_accuracy: 0.9882 - val_loss: 1.6215 - val_categorical_accuracy: 0.6328\n",
      "Epoch 45/50\n",
      "7200/7200 [==============================] - 21s 3ms/step - loss: 0.0357 - categorical_accuracy: 0.9882 - val_loss: 1.6542 - val_categorical_accuracy: 0.6283\n",
      "Epoch 46/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0375 - categorical_accuracy: 0.9883 - val_loss: 1.6481 - val_categorical_accuracy: 0.6333\n",
      "Epoch 47/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.0392 - categorical_accuracy: 0.9883 - val_loss: 1.6471 - val_categorical_accuracy: 0.6261\n",
      "Epoch 48/50\n",
      "7200/7200 [==============================] - 21s 3ms/step - loss: 0.0377 - categorical_accuracy: 0.9869 - val_loss: 1.6439 - val_categorical_accuracy: 0.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50\n",
      "7200/7200 [==============================] - 23s 3ms/step - loss: 0.0353 - categorical_accuracy: 0.9893 - val_loss: 1.6459 - val_categorical_accuracy: 0.6289\n",
      "Epoch 50/50\n",
      "7200/7200 [==============================] - 21s 3ms/step - loss: 0.0353 - categorical_accuracy: 0.9889 - val_loss: 1.6485 - val_categorical_accuracy: 0.6256\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = nb_epoch,\n",
    "                    verbose = True,\n",
    "                    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 385us/step\n",
      "\n",
      "Test categorical_crossentropy: 1.5726948595046997\n",
      "Categorical accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size = batch_size, verbose = True)\n",
    " \n",
    "print('\\nTest categorical_crossentropy:', score[0])\n",
    "print('Categorical accuracy:', score[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
